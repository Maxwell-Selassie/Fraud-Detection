{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c339bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/processed_bank_transaction_data.csv')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c5b878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = joblib.load('../artifacts/preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb85f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STAGE 1: UNSUPERVISED ANOMALY DETECTION (ISOLATION FOREST)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from category_encoders import HashingEncoder\n",
    "# -------------------------\n",
    "# 1. Load your processed dataset\n",
    "# -------------------------\n",
    "# assuming your cleaned dataset is named df_processed\n",
    "# and contains only numerical + encoded columns\n",
    "# (no IDs or date/time strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f195f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# Define features\n",
    "hash_features = ['AccountID','DeviceID','IP Address']\n",
    "hash_encode = HashingEncoder(cols=hash_features, n_components=16)\n",
    "x_hashed = hash_encode.fit_transform(df)\n",
    "\n",
    "x = preprocessor.fit_transform(x_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53759d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 2. Initialize Isolation Forest\n",
    "# -------------------------\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.03,        # expected fraction of anomalies (tune this)\n",
    "    max_samples='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Train the model\n",
    "# -------------------------\n",
    "iso_forest.fit(x)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Get predictions and anomaly scores\n",
    "# -------------------------\n",
    "# predictions: -1 = anomaly, 1 = normal\n",
    "preds = iso_forest.predict(x)\n",
    "scores = iso_forest.decision_function(x)  # higher score = more normal\n",
    "\n",
    "# Convert to readable form\n",
    "df['AnomalyFlag'] = np.where(preds == -1, 1, 0)  # 1 = anomaly/fraud\n",
    "df['AnomalyScore'] = -scores  # invert so higher means more anomalous\n",
    "\n",
    "# -------------------------\n",
    "# 5. Analyze results\n",
    "# -------------------------\n",
    "print(\"Anomalies detected:\", df['AnomalyFlag'].sum(), \"out of\", len(df))\n",
    "\n",
    "# Distribution of scores\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['AnomalyScore'], bins=50, kde=True, color='orange')\n",
    "plt.title(\"Distribution of Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Quick overview of anomaly transactions\n",
    "display(df[df['AnomalyFlag'] == 1].head(10))\n",
    "\n",
    "# -------------------------\n",
    "# 6. Save model artifact\n",
    "# -------------------------\n",
    "joblib.dump(iso_forest, \"../artifacts/isolation_forest_model.joblib\")\n",
    "print(\"âœ… Isolation Forest model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae882b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.cluster import KMeans\n",
    "# x_df = pd.DataFrame(x, columns=feature_names)\n",
    "# x_df['numeric__std'].fillna(0,inplace=True)\n",
    "# # PCA reduction to 10D\n",
    "# pca = PCA(n_components=min(10,x_df.shape[1]), random_state=30)\n",
    "# x_pca = pca.fit_transform(x_df)\n",
    "\n",
    "# df['PC1'] , df['PC2'] = x_pca[:,0] , x_pca[:,1]\n",
    "# print(f'Explained variance by PCA components : {pca.explained_variance_ratio_.sum():.2f}')\n",
    "# # apply k-means clustering on pca components\n",
    "# k_means = KMeans(n_clusters=5, random_state=42)\n",
    "# df['Cluster'] = k_means.fit_predict(x_pca)\n",
    "# # visualise pca vs isolationforest anomalies\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.scatterplot(x='PC1', y='PC2', hue='AnomalyFlag', data=df, palette={1: 'red', 0: 'blue'}, alpha=0.6)\n",
    "# plt.title('Isolation Forest Anomalies (PCA visualizations)')\n",
    "# plt.show()\n",
    "# # Visualize KMeans clusters\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(\n",
    "#     x='PC1', y='PC2',\n",
    "#     hue='Cluster',\n",
    "#     data=df,\n",
    "#     palette='Set2',\n",
    "#     alpha=0.6\n",
    "# )\n",
    "# plt.title(\"KMeans Clusters (PCA Visualization)\")\n",
    "# plt.show()\n",
    "\n",
    "# cross_tab = pd.crosstab(df['Cluster'], df['AnomalyFlag'])\n",
    "# sns.heatmap(cross_tab, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title(\"KMeans Cluster vs Isolation Forest Anomaly Flag\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11752194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...(This May Take A While)\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "----------------------------------------------------------------------\n",
      "Training XGBoost...(This May Take A While)\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "--------------------------------------------------\n",
      "RandomForest Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       488\n",
      "           1       0.39      0.87      0.54        15\n",
      "\n",
      "    accuracy                           0.96       503\n",
      "   macro avg       0.69      0.91      0.76       503\n",
      "weighted avg       0.98      0.96      0.96       503\n",
      "\n",
      "--------------------------------------------------\n",
      "Xgboost Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       488\n",
      "           1       0.43      0.40      0.41        15\n",
      "\n",
      "    accuracy                           0.97       503\n",
      "   macro avg       0.71      0.69      0.70       503\n",
      "weighted avg       0.97      0.97      0.97       503\n",
      "\n",
      "--------------------------------------------------\n",
      "Model Comparison\n",
      "           Model  Accuracy  Precision    Recall  f1_score  roc_auc_score\n",
      "0  RandomForest  0.956262   0.393939  0.866667  0.541667       0.912842\n",
      "1       Xgboost  0.966203   0.428571  0.400000  0.413793       0.691803\n",
      "--------------------------------------------------\n",
      "Best model 'RandomForest' saved as 'RandomForest_fraud_detector.pkl\n"
     ]
    }
   ],
   "source": [
    "y = df['AnomalyFlag']\n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    x,y, test_size=0.2, stratify=y\n",
    ")\n",
    "# cross validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=30)\n",
    "\n",
    "# train random forest model\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=42,class_weight='balanced')\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_params, cv=cv, n_jobs=-1, scoring='f1', verbose=1)\n",
    "print('Training RandomForest...(This May Take A While)')\n",
    "rf_grid.fit(x_train,y_train)\n",
    "\n",
    "# best model for random forest\n",
    "rf_best_ = rf_grid.best_estimator_\n",
    "print('-' * 70)\n",
    "# train xgboost model\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "xgb = XGBClassifier(objective='binary:logistic',random_state=30,eval_metric='logloss')\n",
    "xgb_grid = GridSearchCV(estimator=xgb,param_grid=xgb_params, scoring='f1',verbose=1,n_jobs=-1)\n",
    "print(\"Training XGBoost...(This May Take A While)\")\n",
    "xgb_grid.fit(x_train,y_train)\n",
    "\n",
    "xgb_best_ = xgb_grid.best_estimator_\n",
    "\n",
    "# evaluate both model and pick the best one\n",
    "models = {'RandomForest' : rf_best_, 'Xgboost' : xgb_best_}\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_probs = model.predict_proba(x_test)[:,1]\n",
    "    threshold = 0.2\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    metrics = {\n",
    "        'Model' : name,\n",
    "        'Accuracy' : accuracy_score(y_test,y_pred),\n",
    "        'Precision' : precision_score(y_test,y_pred),\n",
    "        'Recall' : recall_score(y_test,y_pred),\n",
    "        'f1_score' : f1_score(y_test,y_pred),\n",
    "        'roc_auc_score' : roc_auc_score(y_test, y_pred)\n",
    "    }\n",
    "    results.append(metrics)\n",
    "    print('-'*70)\n",
    "    print(f'{name} Classification Report \\n',classification_report(y_test,y_pred))\n",
    "print('-'*70)\n",
    "results_df = pd.DataFrame(results)\n",
    "print('Model Comparison\\n',results_df)\n",
    "\n",
    "# save the best model\n",
    "best_model_name = results_df.sort_values(by='f1_score',ascending=False).iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "joblib.dump(best_model,f'../models/{best_model_name}_fraud_detector.pkl')\n",
    "print('-'*70)\n",
    "print(f\"Best model '{best_model_name}' saved as '{best_model_name}_fraud_detector.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection-r6Xl52aS-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
