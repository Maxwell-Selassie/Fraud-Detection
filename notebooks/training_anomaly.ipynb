{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c339bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/processed_bank_transaction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c5b878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = joblib.load('../artifacts/preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2d410f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = df.drop(columns=['TransactionID','TransactionDate','PreviousTransactionDate']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdb85f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# STAGE 1: UNSUPERVISED ANOMALY DETECTION (ISOLATION FOREST)\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from category_encoders import HashingEncoder\n",
    "# -------------------------\n",
    "# 1. Load your processed dataset\n",
    "# -------------------------\n",
    "# assuming your cleaned dataset is named df_processed\n",
    "# and contains only numerical + encoded columns\n",
    "# (no IDs or date/time strings)\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# Define features\n",
    "X = df.drop(columns=['TransactionID', 'TransactionDate','PreviousTransactionDate'], errors='ignore')\n",
    "hash_features = ['AccountID','DeviceID','IP Address']\n",
    "hash_encode = HashingEncoder(cols=hash_features, n_components=16)\n",
    "x_hashed = hash_encode.fit_transform(X)\n",
    "\n",
    "x = preprocessor.fit_transform(x_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e297d72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.97127547,  1.42371826, -0.55244326, ...,  1.        ,\n",
       "        59.        , 32.        ],\n",
       "       [ 0.26943961,  1.31128706,  0.30531437, ...,  1.        ,\n",
       "        63.        , 27.        ],\n",
       "       [-0.58688162, -1.44327736, -0.90984227, ...,  1.        ,\n",
       "        61.        , 30.        ],\n",
       "       ...,\n",
       "       [-0.92146186,  0.63669986,  0.37679417, ...,  1.        ,\n",
       "        59.        , 25.        ],\n",
       "       [-0.38241973, -1.21841495, -1.43879281, ...,  1.        ,\n",
       "        62.        , 20.        ],\n",
       "       [-0.18676257, -1.16219935, -0.38089174, ...,  0.        ,\n",
       "        60.        , 20.        ]], shape=(2512, 39))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53759d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 2. Initialize Isolation Forest\n",
    "# -------------------------\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.03,        # expected fraction of anomalies (tune this)\n",
    "    max_samples='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 3. Train the model\n",
    "# -------------------------\n",
    "iso_forest.fit(x)\n",
    "\n",
    "# -------------------------\n",
    "# 4. Get predictions and anomaly scores\n",
    "# -------------------------\n",
    "# predictions: -1 = anomaly, 1 = normal\n",
    "preds = iso_forest.predict(x)\n",
    "scores = iso_forest.decision_function(x)  # higher score = more normal\n",
    "\n",
    "# Convert to readable form\n",
    "df['AnomalyFlag'] = np.where(preds == -1, 1, 0)  # 1 = anomaly/fraud\n",
    "df['AnomalyScore'] = -scores  # invert so higher means more anomalous\n",
    "\n",
    "# -------------------------\n",
    "# 5. Analyze results\n",
    "# -------------------------\n",
    "print(\"Anomalies detected:\", df['AnomalyFlag'].sum(), \"out of\", len(df))\n",
    "\n",
    "# Distribution of scores\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df['AnomalyScore'], bins=50, kde=True, color='orange')\n",
    "plt.title(\"Distribution of Anomaly Scores\")\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Quick overview of anomaly transactions\n",
    "display(df[df['AnomalyFlag'] == 1].head(10))\n",
    "\n",
    "# -------------------------\n",
    "# 6. Save model artifact\n",
    "# -------------------------\n",
    "joblib.dump(iso_forest, \"../artifacts/isolation_forest_model.joblib\")\n",
    "print(\"âœ… Isolation Forest model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae882b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection-r6Xl52aS-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
